# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/188gMgSVrxWNHE9nYRCti0nX_ADaszRMW
"""

from google.colab import files
import pandas as pd

# Upload file from your computer
uploaded = files.upload()

# Read the uploaded CSV
df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')
print("the shape of test is :", test_df.shape)
df.head()

#PassengerId - A unique Id for each passenger. Each Id takes the form gggg_pp where gggg indicates a group the passenger is travelling with and pp is their number within the group. People in a group are often family members, but not always.
#HomePlanet - The planet the passenger departed from, typically their planet of permanent residence.
#CryoSleep - Indicates whether the passenger elected to be put into suspended animation for the duration of the voyage. Passengers in cryosleep are confined to their cabins.
#Cabin - The cabin number where the passenger is staying. Takes the form deck/num/side, where side can be either P for Port or S for Starboard.
#Destination - The planet the passenger will be debarking to.
#Age - The age of the passenger.
#VIP - Whether the passenger has paid for special VIP service during the voyage.
#RoomService, FoodCourt, ShoppingMall, Spa, VRDeck - Amount the passenger has billed at each of the Spaceship Titanic's many luxury amenities.
#Name - The first and last names of the passenger.
#Transported - Whether the passenger was transported to another dimension. This is the target, the column you are trying to predict.

# Basic info about the DataFrame
print("Shape (rows, columns):", df.shape)
print("\nColumn Names:", df.columns.tolist())

# Data types and non-null counts
print("\n--- Data Info ---")
print(df.info())

# Summary statistics for numeric columns
print("\n--- Summary Statistics ---")
print(df.describe())

# Max values in each numeric column
print("\n--- Max Values ---")
print(df.max(numeric_only=True))

# Count of missing (null) values per column
print("\n--- Null Values ---")
print(df.isnull().sum())

# Total number of missing values
print("\nTotal Missing Values:", df.isnull().sum().sum())

pd.DataFrame({
    'Unique Values': df.apply(lambda x: x.unique()),
    'Unique Count': df.nunique()
})

print("Shape (rows, columns):", test_df.shape)
print("\nColumn Names:", test_df.columns.tolist())

# Data types and non-null counts
print("\n--- Data Info ---")
print(test_df.info())

# Summary statistics for numeric columns
print("\n--- Summary Statistics ---")
print(test_df.describe())

# Max values in each numeric column
print("\n--- Max Values ---")
print(test_df.max(numeric_only=True))

# Count of missing (null) values per column
print("\n--- Null Values ---")
print(test_df.isnull().sum())

# Total number of missing values
print("\nTotal Missing Values:", test_df.isnull().sum().sum())

pd.DataFrame({
    'Unique Values': test_df.apply(lambda x: x.unique()),
    'Unique Count': test_df.nunique()
})

import numpy as np

# Replace blank/space-only strings with NaN, then count missing values
missing_counts = (df.replace([r'^\s*$','nan', 'NaN', 'NULL', 'null', 'NA', 'na'],np.nan, regex=True).isnull().sum())

print(missing_counts)   #due to this code we came to know that there were 871 null values in name column not only 200

import numpy as np

# Replace blank/space-only strings with NaN, then count missing values
missing_counts_test = (test_df.replace([r'^\s*$','nan', 'NaN', 'NULL', 'null', 'NA', 'na'],np.nan, regex=True).isnull().sum())

print(missing_counts_test)

#the things which needs to get fixed up before filling up null value
# passengerID should split up and form passenger and ID
# cabin can split up in 3
#data types should be true accrding to the data column

# Save PassengerId for submission before splitting
test_ids = test_df["PassengerId"].copy()

#str.split('_', expand=True) ‚Üí splits the string into two parts wherever _ appears


# Split PassengerID into two new columns
df[['passenger_group', 'ID']] = df['PassengerId'].str.split('_', expand=True)
df = df.drop(columns=['PassengerId'])

print(df.head())

test_df[['passenger_group', 'ID']] = test_df['PassengerId'].str.split('_', expand=True)
test_df = test_df.drop(columns=['PassengerId'])

print(test_df.head())

# Split PassengerID into two new columns
df[['deck', 'Cabinnumber','Cabinside']] = df['Cabin'].str.split('/', expand=True)
df = df.drop(columns=['Cabin'])

print(df.head())

test_df[['deck', 'Cabinnumber','Cabinside']] = test_df['Cabin'].str.split('/', expand=True)
test_df = test_df.drop(columns=['Cabin'])

print(test_df.head())

# Data types and non-null counts
print("\n--- Data Info ---")
print(df.info())



missing_counts = (df.replace([r'^\s*$','nan', 'NaN', 'NULL', 'null', 'NA', 'na'],np.nan, regex=True).isnull().sum())

print(missing_counts)

pd.DataFrame({
    'Unique Values': df.apply(lambda x: x.unique()),
    'Unique Count': df.nunique()
})

df.head()

print("\n--- Data Info ---")
print(test_df.info())



missing_counts_test = (test_df.replace([r'^\s*$','nan', 'NaN', 'NULL', 'null', 'NA', 'na'],np.nan, regex=True).isnull().sum())

print(missing_counts_test)

pd.DataFrame({
    'Unique Values': test_df.apply(lambda x: x.unique()),
    'Unique Count': test_df.nunique()
})

test_df.head()

df.info()

pd.DataFrame({
    'Unique Values new': df.apply(lambda x: x.unique()),
    'Unique Count new': df.nunique()
})

#homeplanet-  has 3 features can give one hot labeling
#crysleep - true and false should be change to 0 and 1
#destination - has 3 features can give one hot labeling
#vip - true and false should be change to 0 and 1
# change target variable to int
# passenger group and ID should be in int/float
#deck can ....be in hot label encoding  without doing imputer
#cabin number be in int
#Always split before anything that learns from the data (scaling, imputation, encoding).

#You want to do EDA (skewness, outliers, Pearson correlation) before train-test split.

#But categorical columns are object type, and you‚Äôre thinking: ‚ÄúI need numbers (int/float) first, so maybe I must encode now.‚Äù

#Problem: If you one-hot or label encode before imputation/split, you mess up KNN and risk data leakage.

df_eda = df.copy()
categorical_cols = df.select_dtypes(include=["object", "category"]).columns.tolist()
print(categorical_cols)
for col in categorical_cols:
    df_eda[col] = df_eda[col].astype("category").cat.codes

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt



# 3. Compute correlation matrix
corr_matrix = df_eda.corr(method="pearson")

# 4. Plot heatmap (focus on correlation with target)
target = "Transported"  # replace with your actual target column name
plt.figure(figsize=(10,6))
sns.heatmap(corr_matrix[[target]].sort_values(by=target, ascending=False),
            annot=True, cmap="coolwarm", vmin=-1, vmax=1)

plt.title(f"Correlation of Features with Target: {target}", fontsize=14)
plt.show()

#import seaborn as sns
#import matplotlib.pyplot as plt
#import numpy as np
#from scipy import stats

#numeric_cols = df.select_dtypes(include=["int64","float64"]).columns

#for col in numeric_cols:
    # Drop NaN only for this column
    #col_data = df[col].dropna()

    # Histogram
   # plt.figure(figsize=(6,4))
    #sns.histplot(col_data, kde=True)
    #plt.title(f"Distribution of {col}")
    #plt.show()

    # Boxplot
    #plt.figure(figsize=(6,4))
    #sns.boxplot(x=col_data)
    #plt.title(f"Boxplot of {col}")
    #plt.show()

    # IQR outliers
    #Q1 = col_data.quantile(0.25)
   # Q3 = col_data.quantile(0.75)
    #IQR = Q3 - Q1
    #lower_bound = Q1 - 1.5*IQR
    #upper_bound = Q3 + 1.5*IQR
    #outliers_iqr = col_data[(col_data < lower_bound) | (col_data > upper_bound)]
    #print(f"{col} ‚Üí Outliers (IQR): {len(outliers_iqr)}")

    #if col_data.std() != 0:   # avoid divide-by-zero
        #z_scores = np.abs(stats.zscore(col_data))
        #outliers_z = col_data[z_scores > 3]
        #print(f"{col} ‚Üí Outliers (Z-score): {len(outliers_z)}")
   # else:
    #    print(f"{col} ‚Üí Skipped Z-score (std=0)")

#Fix datatypes & feature extraction
#(e.g., split columns, convert bool to int, etc.)

#EDA (outliers, skewness, correlation)
#Just to understand data.

#Train-test split
#Prevent leakage.

#Numeric imputation with KNN

#Scale numeric features only

#Apply KNNImputer

#Reverse scaling (optional, if you want original units back)

#Categorical imputation
#Fill missing values with mode / "Unknown".

#Encoding categorical features
#(One-Hot, Label Encoding, Target Encoding depending on algo).

#Scaling for modeling

#import seaborn as sns
#import matplotlib.pyplot as plt

# Get categorical/object columns
#cat_cols = df.select_dtypes(include=["object", "category", "bool"]).columns

#for col in cat_cols:
 #   plt.figure(figsize=(6,4))
  #  sns.countplot(data=df, x=col, order=df[col].value_counts().index)
   # plt.title(f"Countplot of {col}")
    #plt.xticks(rotation=45)  # rotate labels if long
    #plt.show()

from sklearn.model_selection import train_test_split

# Suppose your target column is 'target'
X = df.drop(columns=['Transported'])   # features
y = df['Transported']                  # target variable

# Split into 80% train, 20% test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y  # stratify keeps class balance (for classification)
)

print(X_train.shape, X_test.shape)

from sklearn.preprocessing import StandardScaler
from sklearn.impute import KNNImputer



# Choose numeric columns you want to impute
numeric_cols = ['Age',  'RoomService', 'FoodCourt', 'ShoppingMall','Spa','VRDeck']   # <-- put your numeric column names here

# Step 1: scale X_train numeric columns
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train[numeric_cols])

# Step 2: apply KNN imputer on scaled train data
imputer = KNNImputer(n_neighbors=5)
X_train_imputed_scaled = imputer.fit_transform(X_train_scaled)

# Step 3: inverse transform back to original scale
X_train[numeric_cols] = scaler.inverse_transform(X_train_imputed_scaled)

# Step 4: Apply SAME scaler + imputer to X_test
X_test_scaled = scaler.transform(X_test[numeric_cols])
X_test_imputed_scaled = imputer.transform(X_test_scaled)
X_test[numeric_cols] = scaler.inverse_transform(X_test_imputed_scaled)

X_submission_scaled = scaler.transform(test_df[numeric_cols])
X_submission_imputed_scaled = imputer.transform(X_submission_scaled)
test_df[numeric_cols] = scaler.inverse_transform(X_submission_imputed_scaled)

print(X_train.isnull().sum())
print(X_test.isnull().sum())

print(test_df.isnull().sum())

from sklearn.impute import SimpleImputer

# List the categorical columns you want to fill with mode
categorical_cols = ['HomePlanet' , 'CryoSleep', 'Destination', 'VIP', 'deck', 'Cabinnumber', 'Cabinside']   # üëà replace with your own

# Create a mode imputer
mode_imputer = SimpleImputer(strategy='most_frequent')

# Fit on train, transform both train & test
X_train[categorical_cols] = mode_imputer.fit_transform(X_train[categorical_cols])
X_test[categorical_cols] = mode_imputer.transform(X_test[categorical_cols])

test_df[categorical_cols] = mode_imputer.transform(test_df[categorical_cols])

print(X_train.isnull().sum())
print(X_test.isnull().sum())

print(test_df.isnull().sum())

# üëâ One-hot encode a single column (say 'HomePlanet')
col = "HomePlanet"

# Fit on train
train_dummies = pd.get_dummies(X_train[col], prefix=col)

# Apply same categories to test
test_dummies = pd.get_dummies(X_test[col], prefix=col)

test_df_dummies = pd.get_dummies(test_df[col], prefix=col)


# Align train/test so both have same dummy columns
train_dummies, test_dummies = train_dummies.align(test_dummies, join="outer", axis=1, fill_value=0)

# --- Then align both with test ---
train_dummies, test_df_dummies = train_dummies.align(test_df_dummies, join="outer", axis=1, fill_value=0)
test_dummies, test_df_dummies   = test_dummies.align(test_df_dummies, join="outer", axis=1, fill_value=0)

# Drop old column & concat encoded
X_train = pd.concat([X_train.drop(columns=[col]), train_dummies], axis=1)
X_test = pd.concat([X_test.drop(columns=[col]), test_dummies], axis=1)
test_df = pd.concat([test_df.drop(columns=[col]), test_df_dummies], axis=1)
print(X_train.shape, X_test.shape, test_df.shape)

print(train_dummies.isnull().sum().sum())
print(test_dummies.isnull().sum().sum())
print(test_df_dummies.isnull().sum().sum())

from sklearn.preprocessing import LabelEncoder

# Initialize encoder
le = LabelEncoder()

# Fit on train only
X_train["CryoSleep"] = le.fit_transform(X_train["CryoSleep"])

# Apply same mapping to test
X_test["CryoSleep"] = le.transform(X_test["CryoSleep"])
test_df["CryoSleep"] = le.transform(test_df["CryoSleep"])


X_train["VIP"] = le.fit_transform(X_train["VIP"])

# Apply same mapping to test
X_test["VIP"] = le.transform(X_test["VIP"])
test_df["VIP"] = le.transform(test_df["VIP"])

X_train["Cabinside"] = le.fit_transform(X_train["Cabinside"])

# Apply same mapping to test
X_test["Cabinside"] = le.transform(X_test["Cabinside"])
test_df["Cabinside"] = le.transform(test_df["Cabinside"])

col_2 = "Destination"

# Fit on train
train_dummies = pd.get_dummies(X_train[col_2], prefix=col)

# Apply same categories to test
test_dummies = pd.get_dummies(X_test[col_2], prefix=col)

test_df_dummies = pd.get_dummies(test_df[col_2], prefix=col)


# Align train/test so both have same dummy columns
train_dummies, test_dummies = train_dummies.align(test_dummies, join="outer", axis=1, fill_value=0)

# --- Then align both with test ---
train_dummies, test_df_dummies = train_dummies.align(test_df_dummies, join="outer", axis=1, fill_value=0)
test_dummies, test_df_dummies   = test_dummies.align(test_df_dummies, join="outer", axis=1, fill_value=0)

# Drop old column & concat encoded
X_train = pd.concat([X_train.drop(columns=[col_2]), train_dummies], axis=1)
X_test = pd.concat([X_test.drop(columns=[col_2]), test_dummies], axis=1)
test_df = pd.concat([test_df.drop(columns=[col_2]), test_df_dummies], axis=1)

print(X_train.shape, X_test.shape, test_df.shape )

col_3 = "deck"

# Fit on train
train_dummies = pd.get_dummies(X_train[col_3], prefix=col)

# Apply same categories to test
test_dummies = pd.get_dummies(X_test[col_3], prefix=col)

test_df_dummies = pd.get_dummies(test_df[col_3], prefix=col)


# Align train/test so both have same dummy columns
train_dummies, test_dummies = train_dummies.align(test_dummies, join="outer", axis=1, fill_value=0)

# --- Then align both with test ---
train_dummies, test_df_dummies = train_dummies.align(test_df_dummies, join="outer", axis=1, fill_value=0)
test_dummies, test_df_dummies   = test_dummies.align(test_df_dummies, join="outer", axis=1, fill_value=0)

# Drop old column & concat encoded
X_train = pd.concat([X_train.drop(columns=[col_3]), train_dummies], axis=1)
X_test = pd.concat([X_test.drop(columns=[col_3]), test_dummies], axis=1)
test_df = pd.concat([test_df.drop(columns=[col_3]), test_df_dummies], axis=1)

print(X_train.shape, X_test.shape, test_df.shape )

X_train.dtypes
X_test.dtypes
test_df.dtypes

X_train = X_train.drop(columns=["Name"], errors="ignore")
X_test = X_test.drop(columns=["Name"], errors="ignore")
test_df = test_df.drop(columns=["Name"], errors="ignore")
for col in X_train.select_dtypes(include="object").columns:
    X_train[col] = pd.to_numeric(X_train[col], errors="coerce")
    X_test[col] = pd.to_numeric(X_test[col], errors="coerce")
    test_df[col] = pd.to_numeric(test_df[col], errors="coerce")

X_train.dtypes
X_test.dtypes
test_df.dtypes

X_train.head()

# Convert all bool columns to int (0/1)
bool_cols = X_train.select_dtypes(include=['bool']).columns

X_train[bool_cols] = X_train[bool_cols].astype(int)
X_test[bool_cols] = X_test[bool_cols].astype(int)
test_df[bool_cols] = test_df[bool_cols].astype(int)
X_train.sort_index().head()

print(X_train.isnull().sum())

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Train Logistic Regression on PCA-transformed data
log_reg = LogisticRegression(max_iter=1000, random_state=42)
log_reg.fit(X_train, y_train)

# Predictions
y_pred = log_reg.predict(X_test)

# Accuracy
acc = accuracy_score(y_test, y_pred)
print("Accuracy:", acc)

# Detailed metrics
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Confusion Matrix
import matplotlib.pyplot as plt
import seaborn as sns

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Logistic Regression")
plt.show()

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix

# Train KNN (start with k=5, you can tune later)
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

# Predictions
y_pred_knn = knn.predict(X_test)

# Accuracy
acc_knn = accuracy_score(y_test, y_pred_knn)
print("KNN Accuracy:", acc_knn)

# F1 Score (weighted handles imbalance)
f1_knn = f1_score(y_test, y_pred_knn, average='weighted')
print("KNN F1 Score:", f1_knn)

# Detailed metrics
print("\nClassification Report:\n", classification_report(y_test, y_pred_knn))

# Confusion Matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred_knn)
sns.heatmap(cm, annot=True, fmt='d', cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - KNN")
plt.show()

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Train Naive Bayes
nb = GaussianNB()
nb.fit(X_train, y_train)

# Predictions
y_pred_nb = nb.predict(X_test)

# Accuracy
acc_nb = accuracy_score(y_test, y_pred_nb)
print("Naive Bayes Accuracy:", acc_nb)

# F1 Score
f1_nb = f1_score(y_test, y_pred_nb, average='weighted')
print("Naive Bayes F1 Score:", f1_nb)

# Detailed Report
print("\nClassification Report:\n", classification_report(y_test, y_pred_nb))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_nb)
sns.heatmap(cm, annot=True, fmt='d', cmap="Oranges")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Naive Bayes")
plt.show()

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Train Decision Tree (using entropy or gini)
dt = DecisionTreeClassifier(criterion="entropy", random_state=42, max_depth=None)
dt.fit(X_train, y_train)

# Predictions
y_pred_dt = dt.predict(X_test)

# Accuracy
acc_dt = accuracy_score(y_test, y_pred_dt)
print("Decision Tree Accuracy:", acc_dt)

# F1 Score
f1_dt = f1_score(y_test, y_pred_dt, average='weighted')
print("Decision Tree F1 Score:", f1_dt)

# Report
print("\nClassification Report:\n", classification_report(y_test, y_pred_dt))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_dt)
sns.heatmap(cm, annot=True, fmt='d', cmap="Greens")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Decision Tree")
plt.show()

from sklearn.svm import SVC


# Train SVM (RBF kernel is default and works well in many cases)
svm_clf = SVC(kernel='rbf', random_state=42)
svm_clf.fit(X_train, y_train)

# Predictions
y_pred_svm = svm_clf.predict(X_test)

# Accuracy
acc_svm = accuracy_score(y_test, y_pred_svm)
print("SVM Accuracy:", acc_svm)

# F1 Score
f1_svm = f1_score(y_test, y_pred_svm, average='weighted')
print("SVM F1 Score:", f1_svm)

# Report
print("\nClassification Report:\n", classification_report(y_test, y_pred_svm))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_svm)
sns.heatmap(cm, annot=True, fmt='d', cmap="Purples")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - SVM")
plt.show()

from xgboost import XGBClassifier

xgb = XGBClassifier(
    n_estimators=500,
    learning_rate=0.05,
    max_depth=4,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    use_label_encoder=False,
    eval_metric='mlogloss'
)
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)

print("XGBoost Accuracy:", accuracy_score(y_test, y_pred_xgb))
print("XGBoost F1 Score:", f1_score(y_test, y_pred_xgb, average='weighted'))

from sklearn.ensemble import RandomForestClassifier


rf = RandomForestClassifier(
    n_estimators=200,
    max_depth=None,
    random_state=42
)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

print("Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print("Random Forest F1 Score:", f1_score(y_test, y_pred_rf, average='weighted'))

from sklearn.ensemble import GradientBoostingClassifier

gb = GradientBoostingClassifier(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=3,
    random_state=42
)
gb.fit(X_train, y_train)
y_pred_gb = gb.predict(X_test)

print("Gradient Boosting Accuracy:", accuracy_score(y_test, y_pred_gb))
print("Gradient Boosting F1 Score:", f1_score(y_test, y_pred_gb, average='weighted'))

from xgboost import XGBClassifier
from sklearn.model_selection import RandomizedSearchCV


# Base model
xgb_tuned = XGBClassifier(
    objective='binary:logistic',  # use 'multi:softmax' if multiclass
    eval_metric='mlogloss',
    use_label_encoder=False,
    random_state=42
)

# Parameter distributions
param_dist = {
    'n_estimators': np.arange(100, 600, 100),         # number of trees
    'max_depth': np.arange(3, 10, 1),                 # tree depth
    'learning_rate': np.linspace(0.01, 0.3, 10),      # step size
    'subsample': np.linspace(0.6, 1.0, 5),            # row sampling
    'colsample_bytree': np.linspace(0.6, 1.0, 5),     # feature sampling
    'gamma': np.linspace(0, 5, 5),                    # min loss reduction
    'min_child_weight': np.arange(1, 6, 1)            # min child weight
}

# RandomizedSearchCV
rand_xgb = RandomizedSearchCV(
    estimator=xgb_tuned,
    param_distributions=param_dist,
    n_iter=30,          # try 30 random combinations
    scoring='accuracy', # or 'f1_weighted'
    cv=5,
    verbose=1,
    random_state=42,
    n_jobs=-1
)

# Fit
rand_xgb.fit(X_train, y_train)

# Best parameters and CV score
print("Best Parameters:", rand_xgb.best_params_)
print("Best CV Accuracy:", rand_xgb.best_score_)

# Evaluate on test set
best_xgb = rand_xgb.best_estimator_
y_pred_xgb = best_xgb.predict(X_test)

print("Test Accuracy:", accuracy_score(y_test, y_pred_xgb))
print("Test F1 Score:", f1_score(y_test, y_pred_xgb, average='weighted'))
print("\nClassification Report:\n", classification_report(y_test, y_pred_xgb))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_xgb))

import numpy as np
from sklearn.metrics import f1_score

# Predict probabilities on validation set
y_proba = best_xgb.predict_proba(X_test)[:, 1]

# Search thresholds from 0.1 to 0.9
thresholds = np.arange(0.1, 0.9, 0.01)

best_thresh = 0.5
best_f1 = 0

for t in thresholds:
    y_pred_thresh = (y_proba >= t).astype(int)
    f1 = f1_score(y_test, y_pred_thresh)
    if f1 > best_f1:
        best_f1 = f1
        best_thresh = t

print(f"Best Threshold: {best_thresh:.2f}, Best F1: {best_f1:.4f}")

from sklearn.metrics import accuracy_score

y_pred_best = (y_proba >= best_thresh).astype(int)
acc = accuracy_score(y_test, y_pred_best)

print(f"Accuracy at threshold {best_thresh:.2f}: {acc:.4f}")
print(f"F1 Score at threshold {best_thresh:.2f}: {best_f1:.4f}")

# probs in [0,1]
test_proba = best_xgb.predict_proba(test_df)[:, 1]

# hard labels via threshold 0.41
test_pred = (test_proba >= 0.41).astype(int)

# Kaggle Spaceship Titanic expects True/False
submission = pd.DataFrame({
    "PassengerId": test_ids,
    "Transported": test_pred.astype(bool)
})
submission.to_csv("submissionji.csv", index=False)